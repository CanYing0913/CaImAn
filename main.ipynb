{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup Instructions\n",
    "- Ignore this if you already configured a python environment with required dependencies and have a **local** installation of fiji ImageJ.\n",
    "- Follow setup instruction on [ImageJ Github page](https://github.com/imagej/pyimagej) on creating an environment and install pyImageJ. You can choose not to use `mamba` as in the document, but using it will save a bunch of time and get rid of many nontrivial debugging issues. Note that a Java JDK is also required to run ImageJ.\n",
    "- After setup, restart the computer and try to activate the environment. If `print(os.environ['JAVA_HOME'])` prints the corresponding python library path, then you can proceed to the next step.\n",
    "- Install latest [Fiji ImageJ](https://imagej.net/software/fiji/) on your computer. Change the following `app_path` to point to where your `fiji` folder resides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Section 1. Stabilizer\n",
    "\n",
    "- read in raw input tif image sequence and pass through [fiji ImageJ](https://imagej.net/software/fiji/) [Image_Stabilizer](https://imagej.net/plugins/image-stabilizer) plugin\n",
    "- This jupyter notebook requires you have a **local** installation of the latest imagej.\n",
    "- Download the modified version of the plugin, `Image_Stabilizer_Headless.java`, and move it under the folder of `fiji/plugin`. To verify it is working, restart ImageJ and check if `Image Stabilizer Headless` appears under `Plugins` drop down menu.\n",
    "- You don't need to open ImageJ while running this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pipeline_source import *\n",
    "import numpy as np\n",
    "import imagej, scyjava\n",
    "from scyjava import jimport\n",
    "import os, sys, time\n",
    "import cv2, tifffile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Initialize ImageJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "app_path = \"D:\\\\CanYing\\\\Fiji.app\"  # Change this to the directory to local imagej\n",
    "ij = imagej.init(app_path, mode=\"interactive\")\n",
    "\"\"\"\n",
    "Ignore the following errors if any when executing this cell:\n",
    "java.lang.ClassNotFoundException: loci.formats.in.URLReader\n",
    "java.lang.ClassNotFoundException: loci.formats.in.SlideBook6Reader\n",
    "java.lang.ClassNotFoundException: loci.formats.in.ScreenReader\n",
    "java.lang.ClassNotFoundException: loci.formats.in.ZarrReader\n",
    "\"\"\"\n",
    "print(f\"ImageJ version: {ij.getVersion()}\")\n",
    "# if any error occurs executing following cells, check if fiji is the latest version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Choose between image sequence or a single movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# False if a sequence of tif images, True if a single tif movie\n",
    "seq_movie_r = True\n",
    "# Change fpath_in to the path to the folder if use image sequence, or path to the movie.\n",
    "fpath_in = \"E:\\\\case1 Movie_57.tif\" # fpath_in = \"D:\\\\CanYing\\\\Code\\\\Columbia\\\\tiny\"\n",
    "FolderOpener = jimport(\"ij.plugin.FolderOpener\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not seq_movie_r:\n",
    "    imp = FolderOpener.open(fpath_in, \"\")\n",
    "else:\n",
    "    imp = ij.IJ.openImage(fpath_in)\n",
    "dims = imp.getDimensions()\n",
    "print(f\"Loading images with width * height: [{dims[0]} * {dims[1]}], total of {dims[3]} slices.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Run Image_Stabilizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#movie 57 ~360 rotation\n",
    "# Choose the params you want to pass to the stabilizer\n",
    "Transformation = \"Translation\"  # or \"Affine\"\n",
    "MAX_Pyramid_level = 1\n",
    "update_coefficient = 0.90\n",
    "MAX_iteration = 200\n",
    "error_tolerance = 1E-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stime = time.time()\n",
    "ij.IJ.run(imp, \"Image Stabilizer Headless\",\n",
    "       \"transformation=\" + Transformation + \" maximum_pyramid_levels=\" + str(MAX_Pyramid_level) +\n",
    "       \" template_update_coefficient=\" + str(update_coefficient) + \" maximum_iterations=\" + str(MAX_iteration) +\n",
    "       \" error_tolerance=\" + str(error_tolerance))\n",
    "print(f\"Task finishes. Total of {int((time.time() - stime) // 60)} m {int((time.time() - stime) % 60)} s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Save **stabilized** tif image sequence to a desired **empty** directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# False if a sequence of tif images, True if a single tif movie\n",
    "seq_movie_w = True\n",
    "# Filepath to the empty directory if save to a sequence, or the tiff movie name if save to a single movie\n",
    "fpath_out = \"E:\\\\case1 Movie_57_stabilized.tif\"     # You don't have to specify individual name if saving to image sequence, just to an empty folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not seq_movie_w:\n",
    "    # Adjust number of 0s in \"/out_0s1.tif\" for different number of images in the sequence\n",
    "    ij.IJ.run(imp, \"Image Sequence... \", \"format=TIFF save=[\" + fpath_out + \"]\")  # + \"/out_0001.tif\" + \"]\")\n",
    "else:\n",
    "    ij.IJ.saveAs(imp, \"Tiff\", fpath_out)\n",
    "\n",
    "imp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### For Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# False if a sequence of tif images, True if a single tif movie\n",
    "seq_movie_gt = True\n",
    "# Filepath to the empty directory if save to a sequence, or the tiff movie name if save to a single movie\n",
    "fpath_gt = \"E:\\\\Stablized_case1 Movie_57.tif\" # You don't have to specify individual name if saving to image sequence, just to an empty folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# if not seq_movie_gt:\n",
    "#     groundtruth_imp = FolderOpener.open(fpath_gt, \"\")\n",
    "# else:\n",
    "#     print(f\"Opening input movie...\")\n",
    "#     groundtruth_imp = ij.IJ.openVirtual(fpath_gt)\n",
    "# dims = groundtruth_imp.getDimensions()\n",
    "# print(f\"Loading ground truth images with width * height: [{dims[0]} * {dims[1]}], total of {dims[3]} slices.\")\n",
    "if not seq_movie_r:\n",
    "    original_imp = FolderOpener.open(fpath_in, \"\")\n",
    "else:\n",
    "    print(f\"Opening input movie...\")\n",
    "    original_imp = ij.IJ.openVirtual(fpath_in)\n",
    "dims = original_imp.getDimensions()\n",
    "print(f\"Loading original images with width * height: [{dims[0]} * {dims[1]}], total of {dims[3]} slices.\")\n",
    "if not seq_movie_w:\n",
    "    processed_imp = FolderOpener.open(fpath_out, \"\")\n",
    "else:\n",
    "    print(f\"Opening output movie...\")\n",
    "    processed_imp = ij.IJ.openVirtual(fpath_out)\n",
    "dims = processed_imp.getDimensions()\n",
    "print(f\"Loading processed images with width * height: [{dims[0]} * {dims[1]}], total of {dims[3]} slices.\")\n",
    "\n",
    "ij.ui().show(original_imp)\n",
    "ij.ui().show(processed_imp)\n",
    "ij.IJ.run(\"Synchronize Windows\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Closing all Images\n",
    "# if groundtruth_imp is not None:\n",
    "#     groundtruth_imp.close()\n",
    "#     groundtruth_imp = None\n",
    "if original_imp is not None:\n",
    "    original_imp.close()\n",
    "    original_imp = None\n",
    "if processed_imp is not None:\n",
    "    processed_imp.close()\n",
    "    processed_imp = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Resize Movie to save execution time and RAM for later parts.\n",
    "- Note: The reason we don't crop the movie prior to stabilization is the unstabilized input may contain visible translation, which will the crop window much larger than stabilized one. To make sure the object is intact after cropping, we also need a lot of computing resources and time to determine frame by frame, which is not a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fpath_out = r\"E:/Case3 Movie_59.tif\"\n",
    "imp = ij.io().open(fpath_out)\n",
    "image = ij.py.from_java(imp)\n",
    "image = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "histogram = generate_histogram(image, 0)\n",
    "threshold = find_threshold(histogram)\n",
    "print(f\"segmenting image with threshold {threshold}.\")\n",
    "img_seg = apply_segmentation(image, 0, threshold, True)\n",
    "x1, y1, x2, y2 = find_bb_3D(img_seg, stride=500)\n",
    "print(f\"cropping original image with upper-left corner at ({y1}, {x1}); lower-right corner at ({y2}, {x2}).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### You can inspect the crop ROI with running the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.rectangle(image[0, ...], (y1, x1), (y2, x2), color=(255, 0, 0))\n",
    "plt.figure()\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_plt = image[:, x1:x2, y1:y2]\n",
    "plt.figure()\n",
    "plt.imshow(image_plt[0,...], cmap='gray')\n",
    "plt.show()\n",
    "# print(f\"Cropping images with width * height: [{dims[0]} * {dims[1]}], total of {dims[3]} slices.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fpath_resize = r\"E:/resized_case1.tif\"\n",
    "tifffile.imwrite(fpath_resize, image_plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Save cropped movie to file if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fpath_resize = r\"E:/resized_case1.tif\"\n",
    "ij.IJ.saveAs(imp, \"Tiff\", fpath_resize)\n",
    "imp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Quality control for auto-cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imp_before = ij.IJ.openVirtual(fpath_out)\n",
    "imp_after = ij.IJ.openVirtual(fpath_resize)\n",
    "ij.ui().show(imp_before)\n",
    "ij.ui().show(imp_after)\n",
    "ij.IJ.run(\"Synchronize Windows\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Section 2. CaImAn\n",
    "#### Note:\n",
    "Due to incompatibility issue, code block at the end of this section may **not** run correctly. Please see Notes under `Reconstruct Denoised Movie` to make sure **your next half an hour of running the following code is meaningful!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format=\n",
    "                          \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\n",
    "                    # filename=\"/tmp/caiman.log\",\n",
    "                    level=logging.DEBUG)\n",
    "import caiman as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from caiman.source_extraction import cnmf\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import inspect_correlation_pnr, nb_inspect_correlation_pnr\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "import cv2\n",
    "\n",
    "# try:\n",
    "#     cv2.setNumThreads(0)\n",
    "# except:\n",
    "#     pass\n",
    "import bokeh.plotting as bpl\n",
    "import holoviews as hv\n",
    "bpl.output_notebook()\n",
    "hv.notebook_extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Select file(s) to be processed\n",
    "The `download_demo` function will download the specific file for you and return the complete path to the file which will be stored in your `caiman_data` directory. If you adapt this demo for your data make sure to pass the complete path to your file(s). Remember to pass the `fnames` variable as a list. Note that the memory requirement of the CNMF-E algorithm are much higher compared to the standard CNMF algorithm. Test the limits of your system before trying to process very large amounts of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fnames = ['E:\\\\resized_case1.tif']  # filename to be processed\n",
    "#fnames = [download_demo(fnames[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup some parameters\n",
    "We first set some parameters related to the data and motion correction and create a `params` object. We'll modify this object with additional settings later on. You can also set all the parameters at once as demonstrated in the `demo_pipeline.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "frate = 10                       # movie frame rate\n",
    "decay_time = 0.4                 # length of a typical transient in seconds\n",
    "\n",
    "# motion correction parameters\n",
    "motion_correct = False    # flag for performing motion correction\n",
    "pw_rigid = False         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
    "gSig_filt = (3, 3)       # size of high pass spatial filtering, used in 1p data\n",
    "max_shifts = (5, 5)      # maximum allowed rigid shift\n",
    "strides = (48, 48)       # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (24, 24)      # overlap between pathes (size of patch strides+overlaps)\n",
    "max_deviation_rigid = 3  # maximum deviation allowed for patch with respect to rigid shifts\n",
    "border_nan = 'copy'      # replicate values along the boundaries\n",
    "\n",
    "mc_dict = {\n",
    "    'fnames': fnames,\n",
    "    'fr': frate,\n",
    "    'decay_time': decay_time,\n",
    "    'pw_rigid': pw_rigid,\n",
    "    'max_shifts': max_shifts,\n",
    "    'gSig_filt': gSig_filt,\n",
    "    'strides': strides,\n",
    "    'overlaps': overlaps,\n",
    "    'max_deviation_rigid': max_deviation_rigid,\n",
    "    'border_nan': border_nan\n",
    "}\n",
    "\n",
    "opts = params.CNMFParams(params_dict=mc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Motion Correction\n",
    "The background signal in micro-endoscopic data is very strong and makes the motion correction challenging.\n",
    "As a first step the algorithm performs a high pass spatial filtering with a Gaussian kernel to remove the bulk of the background and enhance spatial landmarks.\n",
    "The size of the kernel is given from the parameter `gSig_filt`. If this is left to the default value of `None` then no spatial filtering is performed (default option, used in 2p data).\n",
    "After spatial filtering, the NoRMCorre algorithm is used to determine the motion in each frame. The inferred motion is then applied to the *original* data so no information is lost.\n",
    "\n",
    "The motion corrected files are saved in memory mapped format. If no motion correction is being performed, then the file gets directly memory mapped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if motion_correct:\n",
    "    # do motion correction rigid\n",
    "    mc = MotionCorrect(fnames, dview=None, **opts.get_group('motion'))\n",
    "    mc.motion_correct(save_movie=True)\n",
    "    fname_mc = mc.fname_tot_els if pw_rigid else mc.fname_tot_rig\n",
    "    if pw_rigid:\n",
    "        bord_px = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)),\n",
    "                                     np.max(np.abs(mc.y_shifts_els)))).astype(np.int)\n",
    "    else:\n",
    "        bord_px = np.ceil(np.max(np.abs(mc.shifts_rig))).astype(np.int)\n",
    "        plt.subplot(1, 2, 1); plt.imshow(mc.total_template_rig)  # % plot template\n",
    "        plt.subplot(1, 2, 2); plt.plot(mc.shifts_rig)  # % plot rigid shifts\n",
    "        plt.legend(['x shifts', 'y shifts'])\n",
    "        plt.xlabel('frames')\n",
    "        plt.ylabel('pixels')\n",
    "\n",
    "    bord_px = 0 if border_nan is 'copy' else bord_px\n",
    "    fname_new = cm.save_memmap(fname_mc, base_name='memmap_', order='C',\n",
    "                               border_to_0=bord_px)\n",
    "else:  # if no motion correction just memory map the file\n",
    "    bord_px = 0\n",
    "    fname_new = cm.save_memmap(fnames, base_name='memmap_',\n",
    "                               order='C', border_to_0=0, dview=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load memory mapped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load memory mappable file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "images = Yr.T.reshape((T,) + dims, order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Parameter setting for CNMF-E\n",
    "We now define some parameters for the source extraction step using the CNMF-E algorithm.\n",
    "We construct a new dictionary and use this to modify the *existing* `params` object,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# parameters for source extraction and deconvolution\n",
    "p = 1               # order of the autoregressive system\n",
    "K = None            # upper bound on number of components per patch, in general None\n",
    "gSig = (3, 3)       # gaussian width of a 2D gaussian kernel, which approximates a neuron\n",
    "gSiz = (13, 13)     # average diameter of a neuron, in general 4*gSig+1\n",
    "Ain = None          # possibility to seed with predetermined binary masks\n",
    "merge_thr = .7      # merging threshold, max correlation allowed\n",
    "rf = 40             # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\n",
    "stride_cnmf = 20    # amount of overlap between the patches in pixels\n",
    "#                     (keep it at least large as gSiz, i.e 4 times the neuron size gSig)\n",
    "tsub = 2            # downsampling factor in time for initialization,\n",
    "#                     increase if you have memory problems\n",
    "ssub = 1            # downsampling factor in space for initialization,\n",
    "#                     increase if you have memory problems\n",
    "#                     you can pass them here as boolean vectors\n",
    "low_rank_background = None  # None leaves background of each patch intact,\n",
    "#                     True performs global low-rank approximation if gnb>0\n",
    "gnb = 0             # number of background components (rank) if positive,\n",
    "#                     else exact ring model with following settings\n",
    "#                         gnb= 0: Return background as b and W\n",
    "#                         gnb=-1: Return full rank background B\n",
    "#                         gnb<-1: Don't return background\n",
    "nb_patch = 0        # number of background components (rank) per patch if gnb>0,\n",
    "#                     else it is set automatically\n",
    "min_corr = .8       # min peak value from correlation image\n",
    "min_pnr = 5        # min peak to noise ration from PNR image\n",
    "ssub_B = 2          # additional downsampling factor in space for background\n",
    "ring_size_factor = 1.4  # radius of ring is gSiz*ring_size_factor\n",
    "\n",
    "opts.change_params(params_dict={'method_init': 'corr_pnr',  # use this for 1 photon\n",
    "                                'K': K,\n",
    "                                'gSig': gSig,\n",
    "                                'gSiz': gSiz,\n",
    "                                'merge_thr': merge_thr,\n",
    "                                'p': p,\n",
    "                                'tsub': tsub,\n",
    "                                'ssub': ssub,\n",
    "                                'rf': rf,\n",
    "                                'stride': stride_cnmf,\n",
    "                                'only_init': True,    # set it to True to run CNMF-E\n",
    "                                'nb': gnb,\n",
    "                                'nb_patch': nb_patch,\n",
    "                                'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
    "                                'low_rank_background': low_rank_background,\n",
    "                                'update_background_components': True,  # sometimes setting to False improve the results\n",
    "                                'min_corr': min_corr,\n",
    "                                'min_pnr': min_pnr,\n",
    "                                'normalize_init': False,               # just leave as is\n",
    "                                'center_psf': True,                    # leave as is for 1 photon\n",
    "                                'ssub_B': ssub_B,\n",
    "                                'ring_size_factor': ring_size_factor,\n",
    "                               }\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Inspect summary images and set parameters\n",
    "Check the optimal values of `min_corr` and `min_pnr` by moving slider in the figure that pops up. You can modify them in the `params` object.\n",
    "Note that computing the correlation pnr image can be computationally and memory demanding for large datasets. In this case you can compute\n",
    "only on a subset of the data (the results will not change). You can do that by changing `images[::1]` to `images[::5]` or something similar.\n",
    "This will compute the correlation pnr image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compute some summary images (correlation and peak to noise)\n",
    "cn_filter, pnr = cm.summary_images.correlation_pnr(images[::10], gSig=gSig[0], swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile\n",
    "# inspect the summary images and set the parameters\n",
    "nb_inspect_correlation_pnr(cn_filter, pnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can inspect the correlation and PNR images to select the threshold values for `min_corr` and `min_pnr`. The algorithm will look for components only in places where these value are above the specified thresholds. You can adjust the dynamic range in the plots shown above by choosing the selection tool (third button from the left) and selecting the desired region in the histogram plots on the right of each panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print parameters set above, modify them if necessary based on summary images\n",
    "print(min_corr) # min correlation of peak (from correlation image)\n",
    "print(min_pnr)  # min peak to noise ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Run the CNMF-E algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cnm = cnmf.CNMF(n_processes=6, dview=None, Ain=Ain, params=opts)\n",
    "cnm.fit(images) # 15 min for resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Component Evaluation\n",
    "\n",
    "The processing in patches creates several spurious components. These are filtered out by evaluating each component using three different criteria:\n",
    "\n",
    "- the shape of each component must be correlated with the data at the corresponding location within the FOV\n",
    "- a minimum peak SNR is required over the length of a transient\n",
    "- each shape passes a CNN based classifier\n",
    "\n",
    "<img src=\"../../docs/img/evaluationcomponent.png\"/>\n",
    "After setting some parameters we again modify the existing `params` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "min_SNR = 3  # adaptive way to set threshold on the transient size\n",
    "r_values_min = 0.85  # threshold on space consistency (if you lower more components\n",
    "#                        will be accepted, potentially with worst quality)\n",
    "cnm.params.set('quality', {'min_SNR': min_SNR,\n",
    "                           'rval_thr': r_values_min,\n",
    "                           'use_cnn': False})\n",
    "cnm.estimates.evaluate_components(images, cnm.params, dview=None)\n",
    "\n",
    "print(' ***** ')\n",
    "print('Number of total components: ', len(cnm.estimates.C))\n",
    "print('Number of accepted components: ', len(cnm.estimates.idx_components))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Do some plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cnm.estimates.plot_contours_nb(img=cn_filter, idx=cnm.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "View traces of accepted and rejected components. Note that if you get data rate error you can start Jupyter notebooks using:\n",
    "'jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# accepted components\n",
    "cnm.estimates.hv_view_components(img=cn_filter, idx=cnm.estimates.idx_components,\n",
    "                                denoised_color='red', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# rejected components\n",
    "cnm.estimates.hv_view_components(img=cn_filter, idx=cnm.estimates.idx_components_bad,\n",
    "                                denoised_color='red', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "myidx = cnm.estimates.idx_components\n",
    "print(len(myidx))\n",
    "\n",
    "(x,y) = cnm.estimates.A.shape\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Some instructive movies\n",
    "Play the reconstructed movie alongside the original movie and the (amplified) residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with background\n",
    "cnm.estimates.play_movie(images, q_max=99.5, magnification=2,\n",
    "                                 include_bck=True, gain_res=10, bpx=bord_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# without background\n",
    "cnm.estimates.play_movie(images, q_max=99.9, magnification=2,\n",
    "                                 include_bck=False, gain_res=4, bpx=bord_px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get alll detected spatial components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "(x, y) = cnm.estimates.A.shape\n",
    "# the index of accepted components\n",
    "myidx = cnm.estimates.idx_components\n",
    "\n",
    "coordinate1 = np.reshape(cnm.estimates.A[:, myidx[1]].toarray(), dims, order='F')\n",
    "bl = coordinate1 > 0\n",
    "\n",
    "# setup blank merge arrays. One is from merge, the other is from overlapped areas\n",
    "merged = np.where(bl == True, 0, coordinate1)\n",
    "mhits = np.where(bl == True, 0, coordinate1)\n",
    "blm = merged > 0\n",
    "\n",
    "for i in myidx:\n",
    "    coordinate2 = np.reshape(cnm.estimates.A[:, i].toarray(), dims, order='F')\n",
    "    #%% generate boolean indexing\n",
    "    bl2 = coordinate2 > 0\n",
    "    ct2 = np.sum(bl2)\n",
    "    blm = merged > 0\n",
    "    # identify the overlapped components\n",
    "    bli = np.logical_and(bl2, blm)\n",
    "    cti = np.sum(bli)\n",
    "    # calculate the portion of the overlapped\n",
    "    percent = cti / ct2\n",
    "    print(percent)\n",
    "    if percent < 0.25:\n",
    "        # change the label of this component\n",
    "        merged = np.where(bl2 == True, i + 1, merged)\n",
    "        # exclude the overlapped areas\n",
    "        merged = np.where(bli == True, 0, merged)\n",
    "    else:\n",
    "        # put the overlapped areas here\n",
    "        mhits = np.where(bli == True, 999 + i, mhits)\n",
    "\n",
    "np.savetxt(r\"E:/coor_merged.csv\", merged, delimiter=\",\")\n",
    "np.savetxt(r\"E:/coor_mhits.csv\", mhits, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Extract DF/F values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(components,frames) = cnm.estimates.C.shape\n",
    "print(frames)\n",
    "cnm.estimates.detrend_df_f(quantileMin=8, frames_window=frames)\n",
    "cnm.estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modify the segmentation file of FluoroSNNAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import scipy.io\n",
    "# import numpy as np\n",
    "#\n",
    "# # loat matlab .mat into a dictionary\n",
    "# mat = scipy.io.loadmat(\"E:\\\\caiman_data\\\\caiman2fluro\\\\Segmentation-template.mat\")\n",
    "# # access variable\n",
    "# mat[\"L\"].shape\n",
    "# # remove variable\n",
    "# # save it\n",
    "#\n",
    "# data = np.genfromtxt('E:\\\\caiman_data\\\\demos\\\\notebooks\\\\coor_merged.csv', delimiter=',')\n",
    "# data.shape\n",
    "# mat[\"L\"] = data\n",
    "# scipy.io.savemat('E:\\\\caiman_data\\\\caiman2fluro\\\\pthyon_out_coor_merged.mat', mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualize a component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i = 91\n",
    "plt.figure()\n",
    "plt.imshow(np.reshape(cnm.estimates.A[:, i].toarray(), dims, order='F'))\n",
    "plt.figure()\n",
    "plt.plot(cnm.estimates.C[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i = 91\n",
    "plt.figure()\n",
    "plt.imshow(np.reshape(cnm.estimates.A[:, i].toarray(), dims, order='F'))\n",
    "plt.figure()\n",
    "plt.plot(cnm.estimates.C[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the estimates to local"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c = np.zeros_like(cnm.estimates.C)\n",
    "fname = 'caiman_out_slice'\n",
    "np.save(fname+'_overall.npy', c)\n",
    "for i in range(len(c)):\n",
    "    fname_i = fname + i + '.npy'\n",
    "    np.save(fname_i, c[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## reconstruct denoised movie\n",
    "#### Note: If the following code returns error complaining about an nonexistent parameter called `compress`, that is due to library incompatibility issue. Change code under caiman library file to make the parameter from `compress` to `compression`, and rerun CalmAn all over again.\n",
    "\n",
    "#### Details: The following file paths refer to your conda library path: For example, C:\\Users\\canying\\\\.conda\\env\\caiman\\Lib\\site-packages\\\n",
    "- Under `caiman/base/timeseries.py`, between line 173-191: `tif.write()` and `tif.save()` may complain parameter `compress`.\n",
    "- Please make sure the parameter within your library is compatible with follows:\n",
    "- In `tiffle/tiffle.py`, line 1440 and line 3084: The function may contain `compression` instead of `compress`. If this is the case, change code under `caiman/base/timeseries.py` from `compress=compress` to `compression=compress`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "denoised = cm.movie(cnm.estimates.A.dot(cnm.estimates.C)).reshape(dims + (-1,), order='F').transpose([2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "denoised.save('E:\\\\denoised.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}