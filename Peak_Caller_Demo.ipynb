{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMFEoBV1UBAu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from numpy.linalg import matrix_power\n",
        "import h5py\n",
        "from matplotlib.pyplot import figure\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from numpy import linalg as LA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebooks is about the syntax of using PeakCaller. Please Follow Instructions Below"
      ],
      "metadata": {
        "id": "go_qQvCeUEQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The only functions a user would call(Current Version) are\n",
        "#Detrender_2(does nothing at all)\n",
        "#Find_Peak(finds the peaks)\n",
        "#Print_ALL_Peaks(generate figure for all peaks)\n",
        "#Raster_Plot(generate a dot plot, not raster plot since it would be messy and no different from a dot plot)\n",
        "#Histogram_Height(generate a histogram of heights)\n",
        "#Histogram_Time(generate a histogram of time)\n",
        "#Save_Result\n",
        "#Synchronization\n",
        "#Correlation\n",
        "from scipy.optimize.minpack import inf\n",
        "\n",
        "def flatten(lst):\n",
        "  return [item for sublist in lst for item in sublist]\n",
        "\n",
        "\n",
        "class PeakCaller:\n",
        "  def __init__(self,seq,filename):\n",
        "    self.seq=seq\n",
        "    self.filename=filename[:-5]\n",
        "    self.obs_num=len(seq)\n",
        "    self.length=len(seq[0])\n",
        "    self.smoothed_seq=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.detrended_seq=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.peak_start=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.peak_half_start=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.peak_end=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.peak_half_end=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.peak_loc=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.filterer_peak_loc=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.filterer_peak_loc_2=[[] for _ in range(self.obs_num)]\n",
        "    self.filterer_peak_height_mean=[0 for _ in range(self.obs_num)]\n",
        "    self.filterer_peak_height=[[] for _ in range(self.obs_num)]\n",
        "    self.filterer_peak_rise_time=[[] for _ in range(self.obs_num)]\n",
        "    self.filterer_peak_fall_time=[[] for _ in range(self.obs_num)]\n",
        "    self.filterer_peak_half_start=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.filterer_peak_half_end=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.std_after_removal=[0 for _ in range(self.obs_num)]\n",
        "    self.peak_height=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.peak_height_std=[0 for _ in range(self.obs_num)]\n",
        "    self.peak_height_mean=[0 for _ in range(self.obs_num)]\n",
        "    self.peak_rise_time=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.peak_fall_time=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.non_peak_std=[0 for _ in range(self.obs_num)]\n",
        "    self.series_std=[0 for _ in range(self.obs_num)]\n",
        "    self.series_rel_std=[0 for _ in range(self.obs_num)]\n",
        "    self.series_rel_std_sorted=[[0,i] for i in range(self.obs_num)]\n",
        "    self.matrix_smoother=np.ones((self.length,self.length))/self.length\n",
        "    self.TrendSmoothness=25\n",
        "\n",
        "  def Detrender(self,mark=0,s=60):\n",
        "    if mark==1:\n",
        "      base_mat=np.diag([-2 for i in range(self.length)])+np.diag([1 for i in range(self.length-1)],1)+np.diag([1 for i in range(self.length-1)],-1)\n",
        "      base_mat[0,1]=2\n",
        "      base_mat[self.length-1,self.length-2]=2\n",
        "      base_mat=base_mat/4+np.identity(self.length)\n",
        "      self.matrix_smoother=matrix_power(base_mat,4*s)\n",
        "    for i in range(self.obs_num):\n",
        "      self.smoothed_seq[i]=np.matmul(self.matrix_smoother,self.seq[i])\n",
        "    self.detrended_seq=np.divide(self.seq,np.abs(self.smoothed_seq))\n",
        "    for j in range(self.obs_num):\n",
        "      self.series_std[j]=np.std(self.detrended_seq[j])\n",
        "      self.series_rel_std[j]=self.series_std[j]/(np.max(self.detrended_seq[j])-np.min(self.detrended_seq[j]))\n",
        "      self.series_rel_std_sorted[j][0]=self.series_rel_std[j]\n",
        "    self.series_rel_std_sorted.sort()  \n",
        "  def Detrender_2(self):\n",
        "    self.detrended_seq=self.seq\n",
        "\n",
        "  def Find_Peak(self,lookafter=25,lookbefore=25,rise=16.0,fall=16.0):\n",
        "    rise_ratio=(rise-1)/100\n",
        "    fall_ratio=(fall-1)/100\n",
        "    candidate=[[] for _ in range(self.obs_num)]\n",
        "    pks=[[] for _ in range(self.obs_num)]\n",
        "    for i in range(self.obs_num):\n",
        "      for j in range(self.length):\n",
        "        if j==0 and self.detrended_seq[i][j]>self.detrended_seq[i][j+1]:\n",
        "          candidate[i].append(j)\n",
        "        elif j==self.length-1 and self.detrended_seq[i][j]>self.detrended_seq[i][j-1]:\n",
        "          candidate[i].append(j)\n",
        "        elif j!=0 and j!=self.length-1 and self.detrended_seq[i][j]>self.detrended_seq[i][j+1] and self.detrended_seq[i][j]>self.detrended_seq[i][j-1]:\n",
        "          candidate[i].append(j)\n",
        "      required_rise=rise_ratio\n",
        "      required_fall=fall_ratio\n",
        "      prior_peak=0\n",
        "      for k in candidate[i]:\n",
        "        if k-lookbefore<prior_peak:\n",
        "          continue\n",
        "        #lookbackindex=max(prior_peak,k-lookbefore)\n",
        "        dropit=0\n",
        "        lookbackindex=max(0,k-lookbefore)\n",
        "        minbefore=min(self.detrended_seq[i][lookbackindex:k+1])\n",
        "        min_bf_index=np.argmin(self.detrended_seq[i][lookbackindex:k+1])+lookbackindex\n",
        "        if minbefore<(1-required_rise)*self.detrended_seq[i][k]:\n",
        "          lookaheadthresh=min(self.length-1,k+lookafter)\n",
        "          lookaheadindex=lookaheadthresh\n",
        "          for afterindex in range(k+1,lookaheadthresh+1):\n",
        "            if self.detrended_seq[i][k]<self.detrended_seq[i][afterindex]:\n",
        "              lookaheadindex=afterindex\n",
        "              dropit=1\n",
        "              break\n",
        "          if dropit==1:\n",
        "            continue\n",
        "          minafter=min(self.detrended_seq[i][k:lookaheadindex+1])\n",
        "          min_af_index=np.argmin(self.detrended_seq[i][k:lookaheadindex+1])+k\n",
        "          if minafter<(1-required_rise)*self.detrended_seq[i][k]:\n",
        "            self.peak_loc[i][k]=1\n",
        "            self.peak_start[i][k]=min_bf_index\n",
        "            self.peak_half_start[i][k]=np.where(self.detrended_seq[i][min_bf_index:k+1]<=(minbefore+self.detrended_seq[i][k])/2)[0][-1]+min_bf_index\n",
        "            self.peak_end[i][k]=min_af_index\n",
        "            self.peak_half_end[i][k]=np.where(self.detrended_seq[i][k:min_af_index+1]<=(minafter+self.detrended_seq[i][k])/2)[0][0]+k\n",
        "            self.peak_rise_time[i][k]=k-min_bf_index\n",
        "            self.peak_fall_time[i][k]=min_af_index-k\n",
        "            height=(2*self.detrended_seq[i][k]-minbefore-minafter)/2\n",
        "            #height=max(self.detrended_seq[i][k]-minbefore,self.detrended_seq[i][k]-minafter)\n",
        "            pks[i].append(height)\n",
        "            self.peak_height[i][k]=height\n",
        "            prior_peak=k\n",
        "      next_peak=self.length-1\n",
        "      self.peak_height_std[i]=np.std(np.array(pks[i]))\n",
        "      self.peak_height_mean[i]=np.mean(np.array(pks[i]))\n",
        "      continue\n",
        "      for k in reversed(candidate[i]):\n",
        "        lookafterindex=min(next_peak,k+lookafter)\n",
        "        minafter=min(self.detrended_seq[i][k:lookafterindex+1])\n",
        "        if minafter<(1-required_rise)*self.detrended_seq[i][k]:\n",
        "          next_peak=k\n",
        "        else:\n",
        "          self.peak_loc[i][k]=0\n",
        "    for num in range(self.obs_num):\n",
        "      loc=np.where(self.peak_height[num]>(max(self.detrended_seq[num])-min(self.detrended_seq[num]))/3)[0]\n",
        "      #loc=np.where((self.peak_height[num]>self.peak_height_mean[num]+3*self.peak_height_std[num]))[0]\n",
        "      self.filterer_peak_loc[num][loc]=1\n",
        "      self.filterer_peak_half_start[num][self.peak_half_start[num][loc].astype(int)]=1\n",
        "      self.filterer_peak_half_end[num][self.peak_half_end[num][loc].astype(int)]=1\n",
        "      self.filterer_peak_loc_2[num]=loc\n",
        "      heights=self.peak_height[num][loc]\n",
        "      rise_times=self.peak_rise_time[num][loc]\n",
        "      fall_times=self.peak_fall_time[num][loc]\n",
        "      self.filterer_peak_height_mean[num]=np.mean(heights)\n",
        "      self.filterer_peak_height[num]=list(heights)\n",
        "      self.filterer_peak_rise_time[num]=list(rise_times)\n",
        "      self.filterer_peak_fall_time[num]=list(fall_times)\n",
        "    for num in range(self.obs_num):\n",
        "      index_lst=[1 for _ in range(self.obs_num)]\n",
        "      for ind in self.filterer_peak_loc[num]:\n",
        "        if ind==1:\n",
        "          for i in range(int(self.peak_start[num][i]),int(self.peak_end[num][i]+1)):\n",
        "            index_lst[i]=0\n",
        "      real_index=np.where(np.array(index_lst)==1)\n",
        "      other_points=self.detrended_seq[num][real_index]\n",
        "      self.non_peak_std[num]=np.std(other_points)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def Print_Peak(self,num):\n",
        "    main_data=self.detrended_seq[num]\n",
        "    #loc=np.where((self.peak_height[num]>self.peak_height_mean[num]+3*self.peak_height_std[num]))[0]\n",
        "    loc=np.where(self.peak_height[num]>(max(self.detrended_seq[num])-min(self.detrended_seq[num]))/3)[0]\n",
        "    #print(loc)\n",
        "    highlight=[loc,main_data[loc]]\n",
        "    plt.plot(main_data)\n",
        "    plt.scatter(*highlight, marker='v', color='r')\n",
        "    \n",
        "  def Find_Peak_Good(self,thresh=0.15):\n",
        "    ans=[]\n",
        "    for item in self.series_rel_std_sorted:\n",
        "      if item[0]<thresh:\n",
        "        ans.append(item[1])\n",
        "    return ans\n",
        "  def Find_Peak_Bood(self,thresh=0.15):\n",
        "    ans=[]\n",
        "    for item in self.series_rel_std_sorted:\n",
        "      if item[0]>=thresh:\n",
        "        ans.append(item[1])\n",
        "    return ans\n",
        "  def Print_ALL_Peaks(self):\n",
        "    path=self.filename+\"_All_Peaks\"\n",
        "    fig, axs = plt.subplots(self.obs_num,figsize=(15,4*self.obs_num))\n",
        "    fig.tight_layout()\n",
        "    for j in range(self.obs_num):\n",
        "      main_data=self.detrended_seq[j]\n",
        "      #loc=np.where((self.peak_height[j]>self.peak_height_mean[j]+2*self.peak_height_std[j]))[0]\n",
        "      loc=np.where(self.peak_height[j]>(max(self.detrended_seq[j])-min(self.detrended_seq[j]))/3)[0]\n",
        "      highlight=[loc,main_data[loc]]\n",
        "      axs[j].plot(main_data)\n",
        "      axs[j].scatter(*highlight, marker='v', color='r')\n",
        "    fig.savefig(path+\"_All_Peaks\")\n",
        "  def Raster_Plot(self):\n",
        "    path=self.filename+\"_Raster_Plot\"\n",
        "    x=[]\n",
        "    y=[]\n",
        "    for i in range(self.obs_num):\n",
        "      for j in range(self.length):\n",
        "        if self.filterer_peak_loc[i][j]==1:\n",
        "          x.append(j)\n",
        "          y.append(i)\n",
        "    plt.scatter(x, y, c =\"blue\")\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('ROI(#)')\n",
        "    plt.savefig(path)\n",
        "  def Histogram_Height(self):\n",
        "    path=self.filename+\"_Histogram_Height\"\n",
        "    combined=[item for sublist in self.filterer_peak_height for item in sublist]\n",
        "    plt.hist(combined,bins=10)\n",
        "    plt.xlabel('Peak Height')\n",
        "    plt.ylabel('Counts')\n",
        "    plt.savefig(path)\n",
        "  def Histogram_Time(self):\n",
        "    path=self.filename+\"_Histogram_Time\"\n",
        "    rise_times=[item for sublist in self.filterer_peak_rise_time for item in sublist]\n",
        "    fall_times=[item for sublist in self.filterer_peak_fall_time for item in sublist]\n",
        "    plt.hist([rise_times,fall_times],stacked=True,label=['rise_time','fall_time'])\n",
        "    plt.legend(prop={'size': 10})\n",
        "    plt.xlabel('Peak Height')\n",
        "    plt.savefig(path)\n",
        "\n",
        "\n",
        "  def Save_Result(self):\n",
        "    path1=self.filename+\"_Peak_Data.csv\"\n",
        "    path2=self.filename+'_Series_Data.csv'\n",
        "    path3=self.filename+\"_Summary_Data.csv\"\n",
        "    details = {\n",
        "      'ROI(#)' : [],\n",
        "      'Peak_Number' : [],\n",
        "      'Time' : [],\n",
        "      'Height' : [],\n",
        "      'Rise_Time' : [],\n",
        "      'Fall_Time' : [],\n",
        "      'Total_Time' : [],\n",
        "    }\n",
        "    peak_data=pd.DataFrame(details)\n",
        "    for i in range(len(self.filterer_peak_height)):\n",
        "      for j in range(len(self.filterer_peak_height[i])):\n",
        "        peak_data.loc[len(peak_data.index)] = [int(i),int(j),self.filterer_peak_loc_2[i][j],self.filterer_peak_height[i][j],self.filterer_peak_rise_time[i][j],self.filterer_peak_fall_time[i][j],self.filterer_peak_rise_time[i][j]+self.filterer_peak_fall_time[i][j]]\n",
        "    peak_data=peak_data.astype({'ROI(#)': 'int32','Peak_Number': 'int32','Time': 'int32','Rise_Time': 'int32','Fall_Time': 'int32','Total_Time': 'int32'})\n",
        "    peak_data.to_csv(path1, index=False)\n",
        "    details = {\n",
        "      'ROI(#)' : [],\n",
        "      'Number_of_Peaks' : [],\n",
        "      'Mean_Height' : [],\n",
        "      'Mean_Rise_Time' : [],\n",
        "      'Mean_Fall_Time' : [],\n",
        "      'Mean_Total_Time' : [],\n",
        "      'Mean_InterEvent_Interval' : [],\n",
        "      'Mean_Frequency' : [],\n",
        "    }\n",
        "    series_data=pd.DataFrame(details)\n",
        "    for i in range(len(self.filterer_peak_height)):\n",
        "      interv=0\n",
        "      freq=0\n",
        "      if len(self.filterer_peak_height[i])>=2:\n",
        "        interv=(self.filterer_peak_loc_2[i][-1]-self.filterer_peak_loc_2[i][0])/(len(self.filterer_peak_height[i])-1)\n",
        "        freq=1/interv\n",
        "      series_data.loc[len(series_data.index)] = [i,len(self.filterer_peak_loc_2[i]),np.mean(self.filterer_peak_height[i]),np.mean(self.filterer_peak_rise_time[i]),np.mean(self.filterer_peak_fall_time[i]),np.mean(self.filterer_peak_rise_time[i])+np.mean(self.filterer_peak_fall_time[i]),interv,freq]\n",
        "    series_data.to_csv(path2, index=False)\n",
        "    temp=np.array([max(a,0) for a in list(series_data['Number_of_Peaks']-1)])\n",
        "    val=np.dot(temp,np.array(series_data['Mean_InterEvent_Interval']))/np.sum(temp)\n",
        "    details = {\n",
        "      'Mean_Number_of_Signal_Events' : [np.mean(series_data['Number_of_Peaks'])],\n",
        "      'Standard_Deviation_of_the_Number_of_Signal_Events' : [np.std(series_data['Number_of_Peaks'])],\n",
        "      'Mean_Height_All' : [np.mean(flatten(self.filterer_peak_height))],\n",
        "      'Mean_Rise_Time_All' : [np.mean(flatten(self.filterer_peak_rise_time))],\n",
        "      'Mean_Fall_Time_All' : [np.mean(flatten(self.filterer_peak_fall_time))],\n",
        "      'Mean_Total_Time_All' : [np.mean(flatten(self.filterer_peak_rise_time))+np.mean(flatten(self.filterer_peak_fall_time))],\n",
        "      'Mean_InterEvent_Interval_All' : [val],\n",
        "      'Mean_Frequency_All' : [1/val],\n",
        "    }\n",
        "    summary_data=pd.DataFrame(details)\n",
        "    summary_data.to_csv(path3, index=False)\n",
        "  def Synchronization(self,cluster=False):\n",
        "    path=self.filename+\"_Synchronization_Plot\"\n",
        "    Peak_Regions=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    for i in range(self.obs_num):\n",
        "      Peak_Regions[i][0]=self.filterer_peak_half_start[i][0]-self.filterer_peak_half_end[i][0]\n",
        "      for j in range(1,self.length):\n",
        "        Peak_Regions[i][j]=Peak_Regions[i][j-1]+self.filterer_peak_half_start[i][j]-self.filterer_peak_half_end[i][j]\n",
        "    Peak_Regions=2*Peak_Regions-1\n",
        "    P =np.zeros(self.obs_num*(self.length-1)).reshape(self.obs_num,(self.length-1))\n",
        "    for i in range(self.obs_num):\n",
        "      vec=Peak_Regions[i]\n",
        "      R=np.dot(vec[:,None],vec[None,:])\n",
        "      for j in range(self.length-1):\n",
        "        temp_v=[]\n",
        "        for k in range(j,self.length):\n",
        "          temp_v.append(R[k][k-j])\n",
        "        P[i][j]=np.mean(temp_v)\n",
        "    SI=np.zeros(self.obs_num*self.obs_num).reshape(self.obs_num,self.obs_num)\n",
        "    for i in range(self.obs_num):\n",
        "      for j in range(i+1):\n",
        "        SI[i][j]=np.sum(np.dot(P[i]-np.mean(P[i]),P[j]-np.mean(P[j]))/np.std(P[i])/np.std(P[j]))/(self.length-2)\n",
        "        SI[j][i]=SI[i][j]\n",
        "    SI[np.isnan(SI)]=0\n",
        "    if not cluster:\n",
        "      ax = sns.heatmap(SI)\n",
        "      plt.savefig(path+\"No_Cluster\")\n",
        "      np.savetxt(path+\"No_Cluster.csv\", SI, delimiter=\",\")\n",
        "    else:\n",
        "      e_val, e_vec = LA.eig(SI)\n",
        "      larg_e_val=e_val[e_val>1]\n",
        "      larg_e_vec=(e_vec.T[e_val>1]).T\n",
        "      max_index=[]\n",
        "      max_score=[]\n",
        "      if len(larg_e_val)>0:\n",
        "        ParticipationIndices = np.dot((larg_e_vec*np.abs(larg_e_vec)),np.diag(larg_e_val))\n",
        "        max_index=np.argmax(ParticipationIndices,1)\n",
        "        max_score=np.max(ParticipationIndices,1)\n",
        "        max_index[np.abs(max_score)<np.finfo(float).eps]=0\n",
        "        temp=[]\n",
        "        for i in range(len(max_score)):\n",
        "          temp.append((max_index[i],max_score[i]))\n",
        "        temp=np.array(temp,dtype=\"f,f\")\n",
        "        idx=np.argsort(temp)\n",
        "        SI=SI[idx].T[idx].T\n",
        "      ax = sns.heatmap(SI)\n",
        "      plt.savefig(path+\"With_Cluster\")\n",
        "      np.savetxt(path+\"With_Cluster.csv\", SI, delimiter=\",\")\n",
        "  def Correlation(self):\n",
        "    path=self.filename+\"_Correlation_Plot\"\n",
        "    heat_mat=np.zeros(self.obs_num*self.obs_num).reshape(self.obs_num,self.obs_num)\n",
        "    max_lag=min(50,self.length//2)\n",
        "    for i in range(self.obs_num):\n",
        "      for j in range(i+1):\n",
        "        max_cor=-1\n",
        "        for lag in range(max_lag+1):\n",
        "          A=self.detrended_seq[i,0:(self.length-lag)]\n",
        "          B=self.detrended_seq[j,lag:self.length]\n",
        "          try:\n",
        "            cor=np.sum((A-np.mean(A))*(B-np.mean(B))/np.std(A)/np.std(B))/(self.length-lag-1)\n",
        "          except:\n",
        "            return (A,B,i,j,lag)\n",
        "          max_cor=max(cor,max_cor)\n",
        "        for lag in range(1,max_lag+1):\n",
        "          A=self.detrended_seq[i,lag:self.length]\n",
        "          B=self.detrended_seq[j,0:self.length-lag]\n",
        "          cor=np.sum((A-np.mean(A))*(B-np.mean(B))/np.std(A)/np.std(B))/(self.length-lag-1)\n",
        "          max_cor=max(cor,max_cor)\n",
        "        heat_mat[i][j]=max_cor\n",
        "        heat_mat[j][i]=max_cor\n",
        "    ax = sns.heatmap(heat_mat)\n",
        "    plt.savefig(path)\n",
        "    np.savetxt(path+\".csv\", heat_mat, delimiter=\",\")\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def Print_Peak_Good(self,thresh=0.15):\n",
        "    total=0\n",
        "    for item in self.series_rel_std_sorted:\n",
        "      if item[0]<thresh:\n",
        "        total+=1\n",
        "    fig, axs = plt.subplots(total,figsize=(15,300))\n",
        "    fig.tight_layout()\n",
        "    j=0\n",
        "    for item in self.series_rel_std_sorted:\n",
        "      if item[0]<thresh:\n",
        "        axs[j].plot(self.detrended_seq[item[1]])\n",
        "        j+=1\n",
        "    fig.savefig(\"/content/drive/MyDrive/Good_Ones\")\n",
        "  def Print_Peak_Bad(self,thresh=0.15):\n",
        "    total=0\n",
        "    for item in self.series_rel_std_sorted:\n",
        "      if item[0]>=thresh:\n",
        "        total+=1\n",
        "    fig, axs = plt.subplots(total,figsize=(15,90))\n",
        "    fig.tight_layout()\n",
        "    j=0\n",
        "    for item in self.series_rel_std_sorted:\n",
        "      if item[0]>=thresh:\n",
        "        axs[j].plot(self.detrended_seq[item[1]])\n",
        "        j+=1\n",
        "    fig.savefig(\"/content/drive/MyDrive/Bad_Ones\")"
      ],
      "metadata": {
        "id": "54r_HPwwUfQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here is an example code of how you should use PeakCaller\n",
        "#Assume data is your numpy array\n",
        "#First set the file name\n",
        "filename=\"/content/drive/MyDrive/Case1M57\" #Here I don't know how you read the original data, but you only need to remove extension and put it here\n",
        "Caller_obj_1=PeakCaller(data,filename)\n",
        "Caller_obj_1.Detrender_2()\n",
        "Caller_obj_1.Find_Peak()\n",
        "#The above code generates a PeakCaller object with peaks detected\n",
        "#To save results, do something like this:\n",
        "Caller_obj_1.Synchronization()\n",
        "Caller_obj_1.Save_Result()\n"
      ],
      "metadata": {
        "id": "ZcBUk439V4m5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}