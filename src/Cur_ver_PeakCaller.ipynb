{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#This section is for reading hdf5 file. Just read in your way if running locally or using your own way to mount to google colab\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from numpy.linalg import matrix_power\n",
        "from scipy.signal import find_peaks\n",
        "import h5py\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from matplotlib.pyplot import figure\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from numpy import linalg as LA"
      ],
      "metadata": {
        "id": "W18PGmLL9yOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JhAV7eB3J-i"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize.minpack import inf\n",
        "from numpy import mean, absolute\n",
        "\n",
        "def mad(data, axis=None):\n",
        "    return mean(absolute(data - mean(data, axis)), axis)\n",
        "def flatten(lst):\n",
        "  return [item for sublist in lst for item in sublist]\n",
        "\n",
        "\n",
        "class PeakCaller:\n",
        "  def __init__(self,seq,filename,index=np.array([])):\n",
        "    if index.size==0:\n",
        "      self.index=np.array([i for i in range(len(seq))])\n",
        "    else:\n",
        "      self.index=index\n",
        "    self.num_peak_rec=0\n",
        "    self.seq=seq\n",
        "    self.filename=filename[:-5]\n",
        "    self.obs_num=len(seq)\n",
        "    self.length=len(seq[0])\n",
        "    self.smoothed_seq=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.detrended_seq=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.peak_start=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.peak_half_start=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.peak_end=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.peak_half_end=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.peak_loc=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.filterer_peak_loc=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.filterer_peak_loc_2=[[] for _ in range(self.obs_num)]\n",
        "    self.filterer_peak_height_mean=[0 for _ in range(self.obs_num)]\n",
        "    self.filterer_peak_height_std=[0 for _ in range(self.obs_num)]\n",
        "    self.filterer_peak_height=[[] for _ in range(self.obs_num)]\n",
        "    self.filterer_peak_rise_time=[[] for _ in range(self.obs_num)]\n",
        "    self.filterer_peak_fall_time=[[] for _ in range(self.obs_num)]\n",
        "    self.filterer_peak_half_start=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.filterer_peak_half_end=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.std_after_removal=[0 for _ in range(self.obs_num)]\n",
        "    self.peak_height=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.peak_height_std=[0 for _ in range(self.obs_num)]\n",
        "    self.peak_height_mean=[0 for _ in range(self.obs_num)]\n",
        "    self.peak_rise_time=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.peak_fall_time=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    self.non_peak_std=[0 for _ in range(self.obs_num)]\n",
        "    self.series_std=[0 for _ in range(self.obs_num)]\n",
        "    self.series_mad=[0 for _ in range(self.obs_num)]\n",
        "    self.series_rel_std=[0 for _ in range(self.obs_num)]\n",
        "    self.series_rel_std_sorted=[[0,i] for i in range(self.obs_num)]\n",
        "    self.matrix_smoother=np.ones((self.length,self.length))/self.length\n",
        "    self.candidate_mean_prominence=[0 for _ in range(self.obs_num)]\n",
        "    self.peak_mean_prominence=[0 for _ in range(self.obs_num)]\n",
        "    self.peak_std_prominence=[0 for _ in range(self.obs_num)]\n",
        "    self.TrendSmoothness=25\n",
        "\n",
        "  def Detrender(self,mark=0,s=60):\n",
        "    if mark==1:\n",
        "      base_mat=np.diag([-2 for i in range(self.length)])+np.diag([1 for i in range(self.length-1)],1)+np.diag([1 for i in range(self.length-1)],-1)\n",
        "      base_mat[0,1]=2\n",
        "      base_mat[self.length-1,self.length-2]=2\n",
        "      base_mat=base_mat/4+np.identity(self.length)\n",
        "      self.matrix_smoother=matrix_power(base_mat,4*s)\n",
        "    for i in range(self.obs_num):\n",
        "      self.smoothed_seq[i]=np.matmul(self.matrix_smoother,self.seq[i])\n",
        "    self.detrended_seq=np.divide(self.seq,np.abs(self.smoothed_seq))\n",
        "    for j in range(self.obs_num):\n",
        "      self.series_std[j]=np.std(self.detrended_seq[j])\n",
        "      self.series_rel_std[j]=self.series_std[j]/(np.max(self.detrended_seq[j])-np.min(self.detrended_seq[j]))\n",
        "      self.series_rel_std_sorted[j][0]=self.series_rel_std[j]\n",
        "    self.series_rel_std_sorted.sort()\n",
        "  def Detrender_2(self):\n",
        "    self.detrended_seq=self.seq\n",
        "    for j in range(self.obs_num):\n",
        "      self.series_std[j]=np.std(self.detrended_seq[j])\n",
        "      self.series_mad[j]=mad(self.detrended_seq[j])\n",
        "      self.series_rel_std[j]=self.series_std[j]/(np.max(self.detrended_seq[j])-np.min(self.detrended_seq[j]))\n",
        "      self.series_rel_std_sorted[j][0]=self.series_rel_std[j]\n",
        "    self.series_rel_std_sorted.sort()\n",
        "  def Find_Peak_2(self,lookafter=25,lookbefore=25,rise=16.0,fall=16.0):\n",
        "    rise_ratio=(rise-1)/100\n",
        "    fall_ratio=(fall-1)/100\n",
        "    candidate=[[] for _ in range(self.obs_num)]\n",
        "    pks=[[] for _ in range(self.obs_num)]\n",
        "    for i in range(self.obs_num):\n",
        "      candidate[i], properties=find_peaks(data[i],prominence=(30))\n",
        "      self.candidate_mean_prominence[i]=np.mean(properties['prominences'])\n",
        "      peak_prominence_lst=[]\n",
        "      required_rise=rise_ratio\n",
        "      required_fall=fall_ratio\n",
        "      prior_peak=0\n",
        "      Range=(np.max(self.detrended_seq[i])-np.min(self.detrended_seq[i]))\n",
        "      for j in range(len(candidate[i])):\n",
        "        k=candidate[i][j]\n",
        "        if k-lookbefore<prior_peak:\n",
        "          continue\n",
        "        #lookbackindex=max(prior_peak,k-lookbefore)\n",
        "        dropit=0\n",
        "        lookbackindex=max(0,k-lookbefore)\n",
        "        minbefore=min(self.detrended_seq[i][lookbackindex:k+1])\n",
        "        min_bf_index=np.argmin(self.detrended_seq[i][lookbackindex:k+1])+lookbackindex\n",
        "        if minbefore<self.detrended_seq[i][k]-Range*required_rise:\n",
        "          lookaheadthresh=min(self.length-1,k+lookafter)\n",
        "          lookaheadindex=lookaheadthresh\n",
        "          for afterindex in range(k+1,lookaheadthresh+1):\n",
        "            if self.detrended_seq[i][k]<self.detrended_seq[i][afterindex]:\n",
        "              lookaheadindex=afterindex\n",
        "              dropit=1\n",
        "              break\n",
        "          if dropit==1:\n",
        "            continue\n",
        "          minafter=min(self.detrended_seq[i][k:lookaheadindex+1])\n",
        "          min_af_index=np.argmin(self.detrended_seq[i][k:lookaheadindex+1])+k\n",
        "          if minafter<self.detrended_seq[i][k]-Range*required_rise:\n",
        "            peak_prominence_lst.append(properties['prominences'][j])\n",
        "            self.peak_loc[i][k]=1\n",
        "            self.peak_start[i][k]=min_bf_index\n",
        "            self.peak_half_start[i][k]=np.where(self.detrended_seq[i][min_bf_index:k+1]<=(minbefore+self.detrended_seq[i][k])/2)[0][-1]+min_bf_index\n",
        "            self.peak_end[i][k]=min_af_index\n",
        "            self.peak_half_end[i][k]=np.where(self.detrended_seq[i][k:min_af_index+1]<=(minafter+self.detrended_seq[i][k])/2)[0][0]+k\n",
        "            self.peak_rise_time[i][k]=k-self.peak_half_start[i][k]\n",
        "            self.peak_fall_time[i][k]=self.peak_half_end[i][k]-k\n",
        "            height=(2*self.detrended_seq[i][k]-minbefore-minafter)/2\n",
        "            #height=max(self.detrended_seq[i][k]-minbefore,self.detrended_seq[i][k]-minafter)\n",
        "            pks[i].append(height)\n",
        "            self.peak_height[i][k]=height\n",
        "            prior_peak=k\n",
        "      next_peak=self.length-1\n",
        "      self.peak_height_std[i]=np.std(np.array(pks[i]))\n",
        "      self.peak_height_mean[i]=np.mean(np.array(pks[i]))\n",
        "      self.peak_mean_prominence[i]=np.mean(peak_prominence_lst)\n",
        "      self.peak_std_prominence[i]=np.std(peak_prominence_lst)\n",
        "      continue\n",
        "      for k in reversed(candidate[i]):\n",
        "        lookafterindex=min(next_peak,k+lookafter)\n",
        "        minafter=min(self.detrended_seq[i][k:lookafterindex+1])\n",
        "        if minafter<(1-required_rise)*self.detrended_seq[i][k]:\n",
        "          next_peak=k\n",
        "        else:\n",
        "          self.peak_loc[i][k]=0\n",
        "    for num in range(self.obs_num):\n",
        "      loc=np.where(self.peak_height[num]>0)[0]\n",
        "      #loc=np.where((self.peak_height[num]>self.peak_height_mean[num]+3*self.peak_height_std[num]))[0]\n",
        "      self.filterer_peak_loc[num][loc]=1\n",
        "      self.filterer_peak_half_start[num][self.peak_half_start[num][loc].astype(int)]=1\n",
        "      self.filterer_peak_half_end[num][self.peak_half_end[num][loc].astype(int)]=1\n",
        "      self.filterer_peak_loc_2[num]=loc\n",
        "      heights=self.peak_height[num][loc]\n",
        "      rise_times=self.peak_rise_time[num][loc]\n",
        "      fall_times=self.peak_fall_time[num][loc]\n",
        "      self.filterer_peak_height_mean[num]=np.mean(heights)\n",
        "      self.filterer_peak_height[num]=list(heights)\n",
        "      self.filterer_peak_rise_time[num]=list(rise_times)\n",
        "      self.filterer_peak_fall_time[num]=list(fall_times)\n",
        "    for num in range(self.obs_num):\n",
        "      index_lst=[1 for _ in range(self.obs_num)]\n",
        "      for ind in self.filterer_peak_loc[num]:\n",
        "        if ind==1:\n",
        "          for i in range(int(self.peak_start[num][i]),int(self.peak_end[num][i]+1)):\n",
        "            index_lst[i]=0\n",
        "      real_index=np.where(np.array(index_lst)==1)\n",
        "      other_points=self.detrended_seq[num][real_index]\n",
        "      self.non_peak_std[num]=np.std(other_points)\n",
        "\n",
        "  def Find_Peak(self,lookafter=25,lookbefore=25,rise=16.0,fall=16.0):\n",
        "    rise_ratio=(rise-1)/100\n",
        "    fall_ratio=(fall-1)/100\n",
        "    candidate=[[] for _ in range(self.obs_num)]\n",
        "    pks=[[] for _ in range(self.obs_num)]\n",
        "    for i in range(self.obs_num):\n",
        "      for j in range(self.length):\n",
        "        if j==0 and self.detrended_seq[i][j]>self.detrended_seq[i][j+1]:\n",
        "          candidate[i].append(j)\n",
        "        elif j==self.length-1 and self.detrended_seq[i][j]>self.detrended_seq[i][j-1]:\n",
        "          candidate[i].append(j)\n",
        "        elif j!=0 and j!=self.length-1 and self.detrended_seq[i][j]>self.detrended_seq[i][j+1] and self.detrended_seq[i][j]>self.detrended_seq[i][j-1]:\n",
        "          candidate[i].append(j)\n",
        "      required_rise=rise_ratio\n",
        "      required_fall=fall_ratio\n",
        "      prior_peak=0\n",
        "      for k in candidate[i]:\n",
        "        if k-lookbefore<prior_peak:\n",
        "          continue\n",
        "        #lookbackindex=max(prior_peak,k-lookbefore)\n",
        "        dropit=0\n",
        "        lookbackindex=max(0,k-lookbefore)\n",
        "        minbefore=min(self.detrended_seq[i][lookbackindex:k+1])\n",
        "        min_bf_index=np.argmin(self.detrended_seq[i][lookbackindex:k+1])+lookbackindex\n",
        "        if minbefore<(1-required_rise)*self.detrended_seq[i][k]:\n",
        "          lookaheadthresh=min(self.length-1,k+lookafter)\n",
        "          lookaheadindex=lookaheadthresh\n",
        "          for afterindex in range(k+1,lookaheadthresh+1):\n",
        "            if self.detrended_seq[i][k]<self.detrended_seq[i][afterindex]:\n",
        "              lookaheadindex=afterindex\n",
        "              dropit=1\n",
        "              break\n",
        "          if dropit==1:\n",
        "            continue\n",
        "          minafter=min(self.detrended_seq[i][k:lookaheadindex+1])\n",
        "          min_af_index=np.argmin(self.detrended_seq[i][k:lookaheadindex+1])+k\n",
        "          if minafter<(1-required_rise)*self.detrended_seq[i][k]:\n",
        "            self.peak_loc[i][k]=1\n",
        "            self.peak_start[i][k]=min_bf_index\n",
        "            self.peak_half_start[i][k]=np.where(self.detrended_seq[i][min_bf_index:k+1]<=(minbefore+self.detrended_seq[i][k])/2)[0][-1]+min_bf_index\n",
        "            self.peak_end[i][k]=min_af_index\n",
        "            self.peak_half_end[i][k]=np.where(self.detrended_seq[i][k:min_af_index+1]<=(minafter+self.detrended_seq[i][k])/2)[0][0]+k\n",
        "            self.peak_rise_time[i][k]=k-self.peak_half_start[i][k]\n",
        "            self.peak_fall_time[i][k]=self.peak_half_end[i][k]-k\n",
        "            height=(2*self.detrended_seq[i][k]-minbefore-minafter)/2\n",
        "            #height=max(self.detrended_seq[i][k]-minbefore,self.detrended_seq[i][k]-minafter)\n",
        "            pks[i].append(height)\n",
        "            self.peak_height[i][k]=height\n",
        "            prior_peak=k\n",
        "      next_peak=self.length-1\n",
        "      self.peak_height_std[i]=np.std(np.array(pks[i]))\n",
        "      self.peak_height_mean[i]=np.mean(np.array(pks[i]))\n",
        "      continue\n",
        "      for k in reversed(candidate[i]):\n",
        "        lookafterindex=min(next_peak,k+lookafter)\n",
        "        minafter=min(self.detrended_seq[i][k:lookafterindex+1])\n",
        "        if minafter<(1-required_rise)*self.detrended_seq[i][k]:\n",
        "          next_peak=k\n",
        "        else:\n",
        "          self.peak_loc[i][k]=0\n",
        "    for num in range(self.obs_num):\n",
        "      loc=np.where(self.peak_height[num]>(max(self.detrended_seq[num])-min(self.detrended_seq[num]))/3)[0]\n",
        "      #loc=np.where((self.peak_height[num]>self.peak_height_mean[num]+3*self.peak_height_std[num]))[0]\n",
        "      self.filterer_peak_loc[num][loc]=1\n",
        "      self.filterer_peak_half_start[num][self.peak_half_start[num][loc].astype(int)]=1\n",
        "      self.filterer_peak_half_end[num][self.peak_half_end[num][loc].astype(int)]=1\n",
        "      self.filterer_peak_loc_2[num]=loc\n",
        "      heights=self.peak_height[num][loc]\n",
        "      rise_times=self.peak_rise_time[num][loc]\n",
        "      fall_times=self.peak_fall_time[num][loc]\n",
        "      self.filterer_peak_height_mean[num]=np.mean(heights)\n",
        "      self.filterer_peak_height_std[num]=np.std(heights)\n",
        "      self.filterer_peak_height[num]=list(heights)\n",
        "      self.filterer_peak_rise_time[num]=list(rise_times)\n",
        "      self.filterer_peak_fall_time[num]=list(fall_times)\n",
        "    for num in range(self.obs_num):\n",
        "      index_lst=[1 for _ in range(self.length)]\n",
        "      for ind in range(len(self.filterer_peak_loc[num])):\n",
        "        if self.filterer_peak_loc[num][ind]==1:\n",
        "          for i in range(int(self.peak_start[num][ind]),int(self.peak_end[num][ind]+1)):\n",
        "            index_lst[i]=0\n",
        "      real_index=np.where(np.array(index_lst)==1)\n",
        "      other_points=self.detrended_seq[num][real_index]\n",
        "      self.non_peak_std[num]=np.std(other_points)\n",
        "    self.num_peak_rec=[len(self.filterer_peak_loc_2[i]) for i in range(self.obs_num)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def Print_Peak(self,num):\n",
        "    main_data=self.detrended_seq[num]\n",
        "    #loc=np.where((self.peak_height[num]>self.peak_height_mean[num]+3*self.peak_height_std[num]))[0]\n",
        "    loc=np.where(self.peak_height[num]>(max(self.detrended_seq[num])-min(self.detrended_seq[num]))/3)[0]\n",
        "    #loc=np.where(self.peak_height[num]>0)[0]\n",
        "    #print(loc)\n",
        "    highlight=[loc,main_data[loc]]\n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.plot(main_data)\n",
        "    plt.scatter(*highlight, marker='v', color='r')\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel('Intensity')\n",
        "    plt.title('ROI#'+str(self.index[num]))\n",
        "\n",
        "  def Find_Peak_Good(self,thresh=0.15):\n",
        "    ans=[]\n",
        "    for item in self.series_rel_std_sorted:\n",
        "      if item[0]<thresh:\n",
        "        ans.append(item[1])\n",
        "    return ans\n",
        "  def Find_Peak_Bood(self,thresh=0.15):\n",
        "    ans=[]\n",
        "    for item in self.series_rel_std_sorted:\n",
        "      if item[0]>=thresh:\n",
        "        ans.append(item[1])\n",
        "    return ans\n",
        "  def Print_ALL_Peaks(self):\n",
        "    path=self.filename+\"_All_Peaks\"\n",
        "    for i in range(self.obs_num//100+1):\n",
        "      num_left=min(self.obs_num-100*i,100)\n",
        "      if num_left<=0:\n",
        "        break\n",
        "      with plt.rc_context({'xtick.color':'black', 'ytick.color':'black'}):\n",
        "        fig, axs = plt.subplots(num_left,figsize=(15,4*num_left))\n",
        "        fig.tight_layout()\n",
        "        for j in range(100*i,100*i+num_left):\n",
        "          main_data=self.detrended_seq[j]\n",
        "          #loc=np.where((self.peak_height[j]>self.peak_height_mean[j]+2*self.peak_height_std[j]))[0]\n",
        "          loc=np.where(self.peak_height[j]>(max(self.detrended_seq[j])-min(self.detrended_seq[j]))/3)[0]\n",
        "          #loc=np.where(self.peak_height[j]>0)[0]\n",
        "          highlight=[loc,main_data[loc]]\n",
        "          axs[j%100].plot(main_data)\n",
        "          axs[j%100].set_xlabel('Time')\n",
        "          axs[j%100].set_ylabel('Intensity')\n",
        "          axs[j%100].set_title('ROI#'+str(self.index[100*i+j]))\n",
        "          axs[j%100].scatter(*highlight, marker='v', color='r')\n",
        "        fig.tight_layout(pad=5.0)\n",
        "        fig.savefig(path+\"_All_Peaks_\"+str(i))\n",
        "        fig.clf()\n",
        "        plt.close()\n",
        "  def Raster_Plot(self):\n",
        "    path=self.filename+\"_Raster_Plot\"\n",
        "    x=[]\n",
        "    y=[]\n",
        "    for i in range(self.obs_num):\n",
        "      for j in range(self.length):\n",
        "        if self.filterer_peak_loc[i][j]==1:\n",
        "          x.append(j)\n",
        "          y.append(i)\n",
        "    plt.scatter(x, y, color=(0,0.8,0))\n",
        "    plt.xlabel('Time(s)')\n",
        "    plt.ylabel('ROI_Index(#)')\n",
        "    plt.show()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "  def Histogram_Height(self):\n",
        "    path=self.filename+\"_Histogram_Height\"\n",
        "    combined=[item for sublist in self.filterer_peak_height for item in sublist]\n",
        "    plt.hist(combined,bins=10,edgecolor='black',color=(0.6,0.6,0.75))\n",
        "    plt.xlabel('height of peak')\n",
        "    plt.ylabel('number of events')\n",
        "    #plt.show()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "  def Histogram_Time(self):\n",
        "    path=self.filename+\"_Histogram_Time\"\n",
        "    rise_times=[item for sublist in self.filterer_peak_rise_time for item in sublist]\n",
        "    fall_times=[item for sublist in self.filterer_peak_fall_time for item in sublist]\n",
        "    plt.hist([fall_times,rise_times],stacked=True,label=['fall_time','rise_time'],color=[(0.6,0.2,0.2),(0.6,0.6,0.6)],edgecolor='black')\n",
        "    plt.legend(prop={'size': 10})\n",
        "    plt.xlabel('time (s)')\n",
        "    plt.ylabel('number of events')\n",
        "    #plt.show()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "#Path here needs csv extension\n",
        "  def Save_Result(self):\n",
        "    path1=self.filename+\"_Peak_Data.csv\"\n",
        "    path2=self.filename+'_Series_Data.csv'\n",
        "    path3=self.filename+\"_Summary_Data.csv\"\n",
        "    details = {\n",
        "      'ROI(#)' : [],\n",
        "      'Peak_Number' : [],\n",
        "      'Time' : [],\n",
        "      'Height' : [],\n",
        "      'Rise_Time' : [],\n",
        "      'Fall_Time' : [],\n",
        "      'Total_Time' : [],\n",
        "    }\n",
        "    peak_data=pd.DataFrame(details)\n",
        "    for i in range(len(self.filterer_peak_height)):\n",
        "      for j in range(len(self.filterer_peak_height[i])):\n",
        "        peak_data.loc[len(peak_data.index)] = [int(self.index[i]),int(j),self.filterer_peak_loc_2[i][j],self.filterer_peak_height[i][j],self.filterer_peak_rise_time[i][j],self.filterer_peak_fall_time[i][j],self.filterer_peak_rise_time[i][j]+self.filterer_peak_fall_time[i][j]]\n",
        "    peak_data=peak_data.astype({'ROI(#)': 'int32','Peak_Number': 'int32','Time': 'int32','Rise_Time': 'int32','Fall_Time': 'int32','Total_Time': 'int32'})\n",
        "    peak_data.to_csv(path1, index=False)\n",
        "    details = {\n",
        "      'ROI(#)' : [],\n",
        "      'Number_of_Peaks' : [],\n",
        "      'Mean_Height' : [],\n",
        "      'Mean_Rise_Time' : [],\n",
        "      'Mean_Fall_Time' : [],\n",
        "      'Mean_Total_Time' : [],\n",
        "      'Mean_InterEvent_Interval' : [],\n",
        "      'Mean_Frequency' : [],\n",
        "    }\n",
        "    series_data=pd.DataFrame(details)\n",
        "    for i in range(len(self.filterer_peak_height)):\n",
        "      interv=0\n",
        "      freq=0\n",
        "      if len(self.filterer_peak_height[i])>=2:\n",
        "        interv=(self.filterer_peak_loc_2[i][-1]-self.filterer_peak_loc_2[i][0])/(len(self.filterer_peak_height[i])-1)\n",
        "        freq=1/interv\n",
        "      series_data.loc[len(series_data.index)] = [self.index[i],len(self.filterer_peak_loc_2[i]),np.mean(self.filterer_peak_height[i]),np.mean(self.filterer_peak_rise_time[i]),np.mean(self.filterer_peak_fall_time[i]),np.mean(self.filterer_peak_rise_time[i])+np.mean(self.filterer_peak_fall_time[i]),interv,freq]\n",
        "    series_data.to_csv(path2, index=False)\n",
        "    temp=np.array([max(a,0) for a in list(series_data['Number_of_Peaks']-1)])\n",
        "    val=np.dot(temp,np.array(series_data['Mean_InterEvent_Interval']))/np.sum(temp)\n",
        "    interlev_lst=[]\n",
        "    base1=np.array(series_data['Mean_InterEvent_Interval'])\n",
        "    for i in range(len(temp)):\n",
        "      interlev_lst+=[base1[i]]*int(temp[i])\n",
        "    details = {\n",
        "      'Mean_Number_of_Signal_Events' : [np.mean(series_data['Number_of_Peaks'])],\n",
        "      'Standard_Deviation_of_the_Number_of_Signal_Events' : [np.std(series_data['Number_of_Peaks'])],\n",
        "      'Mean_Height_All' : [np.mean(flatten(self.filterer_peak_height))],\n",
        "      'Std_Height_All' : [np.std(flatten(self.filterer_peak_height))],\n",
        "      'Mean_Rise_Time_All' : [np.mean(flatten(self.filterer_peak_rise_time))],\n",
        "      'Std_Rise_Time_All' : [np.std(flatten(self.filterer_peak_rise_time))],\n",
        "      'Mean_Fall_Time_All' : [np.mean(flatten(self.filterer_peak_fall_time))],\n",
        "      'Std_Fall_Time_All' : [np.std(flatten(self.filterer_peak_fall_time))],\n",
        "      'Mean_Total_Time_All' : [np.mean(flatten(self.filterer_peak_rise_time))+np.mean(flatten(self.filterer_peak_fall_time))],\n",
        "      'Std_Total_Time_All' : [np.std(np.add(flatten(self.filterer_peak_rise_time),flatten(self.filterer_peak_fall_time)))],\n",
        "      'Mean_InterEvent_Interval_All' : [val],\n",
        "      'Std_InterEvent_Interval_All' : [np.std(interlev_lst)],\n",
        "      'Mean_Frequency_All' : [1/val],\n",
        "    }\n",
        "    summary_data=pd.DataFrame(details)\n",
        "    summary_data.to_csv(path3, index=False)\n",
        "  def Synchronization(self,cluster=False):\n",
        "    path=self.filename+\"_Synchronization_Plot\"\n",
        "    Peak_Regions=np.zeros(self.obs_num*self.length).reshape(self.obs_num,self.length)\n",
        "    for i in range(self.obs_num):\n",
        "      Peak_Regions[i][0]=self.filterer_peak_half_start[i][0]-self.filterer_peak_half_end[i][0]\n",
        "      for j in range(1,self.length):\n",
        "        Peak_Regions[i][j]=Peak_Regions[i][j-1]+self.filterer_peak_half_start[i][j]-self.filterer_peak_half_end[i][j]\n",
        "    Peak_Regions=2*Peak_Regions-1\n",
        "    P =np.zeros(self.obs_num*(self.length-1)).reshape(self.obs_num,(self.length-1))\n",
        "    for i in range(self.obs_num):\n",
        "      vec=Peak_Regions[i]\n",
        "      R=np.dot(vec[:,None],vec[None,:])\n",
        "      for j in range(self.length-1):\n",
        "        temp_v=[]\n",
        "        for k in range(j,self.length):\n",
        "          temp_v.append(R[k][k-j])\n",
        "        P[i][j]=np.mean(temp_v)\n",
        "    SI=np.zeros(self.obs_num*self.obs_num).reshape(self.obs_num,self.obs_num)\n",
        "    for i in range(self.obs_num):\n",
        "      for j in range(i+1):\n",
        "        SI[i][j]=np.sum(np.dot(P[i]-np.mean(P[i]),P[j]-np.mean(P[j]))/np.std(P[i])/np.std(P[j]))/(self.length-2)\n",
        "        SI[j][i]=SI[i][j]\n",
        "    SI[np.isnan(SI)]=0\n",
        "    if not cluster:\n",
        "      ax = sns.heatmap(SI,cmap='jet',linecolor='black')\n",
        "      ax.invert_yaxis()\n",
        "      #plt.show()\n",
        "      plt.savefig(path+\"No_Cluster\")\n",
        "      plt.close()\n",
        "      np.savetxt(path+\"No_Cluster.csv\", SI, delimiter=\",\")\n",
        "    else:\n",
        "      e_val, e_vec = LA.eig(SI)\n",
        "      larg_e_val=e_val[e_val>1]\n",
        "      larg_e_vec=(e_vec.T[e_val>1]).T\n",
        "      max_index=[]\n",
        "      max_score=[]\n",
        "      if len(larg_e_val)>0:\n",
        "        ParticipationIndices = np.dot((larg_e_vec*np.abs(larg_e_vec)),np.diag(larg_e_val))\n",
        "        max_index=np.argmax(ParticipationIndices,1)\n",
        "        max_score=np.max(ParticipationIndices,1)\n",
        "        max_index[np.abs(max_score)<np.finfo(float).eps]=0\n",
        "        temp=[]\n",
        "        for i in range(len(max_score)):\n",
        "          temp.append((max_index[i],max_score[i]))\n",
        "        temp=np.array(temp,dtype=\"f,f\")\n",
        "        idx=np.argsort(temp)\n",
        "        SI=SI[idx].T[idx].T\n",
        "      ax = sns.heatmap(SI,cmap='jet',linecolor='black')\n",
        "      ax.invert_yaxis()\n",
        "      #plt.show()\n",
        "      plt.savefig(path+\"With_Cluster\")\n",
        "      np.savetxt(path+\"With_Cluster.csv\", SI, delimiter=\",\")\n",
        "      plt.close()\n",
        "  def Correlation(self):\n",
        "    path=self.filename+\"_Correlation_Plot\"\n",
        "    heat_mat=np.zeros(self.obs_num*self.obs_num).reshape(self.obs_num,self.obs_num)\n",
        "    max_lag=min(50,self.length//2)\n",
        "    for i in range(self.obs_num):\n",
        "      for j in range(i+1):\n",
        "        max_cor=-1\n",
        "        for lag in range(max_lag+1):\n",
        "          A=self.detrended_seq[i,0:(self.length-lag)]\n",
        "          B=self.detrended_seq[j,lag:self.length]\n",
        "          try:\n",
        "            cor=np.sum((A-np.mean(A))*(B-np.mean(B))/np.std(A)/np.std(B))/(self.length-lag-1)\n",
        "          except:\n",
        "            return (A,B,i,j,lag)\n",
        "          max_cor=max(cor,max_cor)\n",
        "        for lag in range(1,max_lag+1):\n",
        "          A=self.detrended_seq[i,lag:self.length]\n",
        "          B=self.detrended_seq[j,0:self.length-lag]\n",
        "          cor=np.sum((A-np.mean(A))*(B-np.mean(B))/np.std(A)/np.std(B))/(self.length-lag-1)\n",
        "          max_cor=max(cor,max_cor)\n",
        "        heat_mat[i][j]=max_cor\n",
        "        heat_mat[j][i]=max_cor\n",
        "    ax = sns.heatmap(heat_mat,cmap='jet',linecolor='black',vmin=-1, vmax=1)\n",
        "    ax.invert_yaxis()\n",
        "    #plt.show()\n",
        "    plt.savefig(path)\n",
        "    np.savetxt(path+\".csv\", heat_mat, delimiter=\",\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def Print_Peak_Good(self,thresh=0.15):\n",
        "    total=0\n",
        "    for item in self.series_rel_std_sorted:\n",
        "      if item[0]<thresh:\n",
        "        total+=1\n",
        "    fig, axs = plt.subplots(total,figsize=(15,300))\n",
        "    fig.tight_layout()\n",
        "    j=0\n",
        "    for item in self.series_rel_std_sorted:\n",
        "      if item[0]<thresh:\n",
        "        axs[j].plot(self.detrended_seq[item[1]])\n",
        "        j+=1\n",
        "    fig.savefig(\"/content/drive/MyDrive/Good_Ones\")\n",
        "  def Print_Peak_Bad(self,thresh=0.15):\n",
        "    total=0\n",
        "    for item in self.series_rel_std_sorted:\n",
        "      if item[0]>=thresh:\n",
        "        total+=1\n",
        "    fig, axs = plt.subplots(total,figsize=(15,90))\n",
        "    fig.tight_layout()\n",
        "    j=0\n",
        "    for item in self.series_rel_std_sorted:\n",
        "      if item[0]>=thresh:\n",
        "        axs[j].plot(self.detrended_seq[item[1]])\n",
        "        j+=1\n",
        "    fig.savefig(\"/content/drive/MyDrive/Bad_Ones\")\n",
        "  def Filter_Series(self,model_root):\n",
        "    clf= pickle.load(open(model_root, 'rb'))\n",
        "    ratio=np.array(self.filterer_peak_height_mean)/np.array(self.non_peak_std)\n",
        "    ratio[np.isnan(ratio)]=1\n",
        "    rel_std=self.series_rel_std\n",
        "    X=np.array([[0.0] for _ in range(self.obs_num)])\n",
        "    Z=np.array([0.0 for _ in range(self.obs_num)])\n",
        "    for i in range(len(X)):\n",
        "      X[i][0]=ratio[i]\n",
        "      Z[i]=rel_std[i]\n",
        "    W=np.array(self.series_mad)\n",
        "    details = {\n",
        "      'ROI(#)' : [],\n",
        "      'Number_of_Peaks' : [],\n",
        "      'Mean_Height' : [],\n",
        "      'Mean_Rise_Time' : [],\n",
        "      'Mean_Fall_Time' : [],\n",
        "      'Mean_Total_Time' : [],\n",
        "      'Mean_InterEvent_Interval' : [],\n",
        "      'Mean_Frequency' : [],\n",
        "    }\n",
        "    series_data=pd.DataFrame(details)\n",
        "    for i in range(len(self.filterer_peak_height)):\n",
        "      interv=0\n",
        "      freq=0\n",
        "      if len(self.filterer_peak_height[i])>=2:\n",
        "        interv=(self.filterer_peak_loc_2[i][-1]-self.filterer_peak_loc_2[i][0])/(len(self.filterer_peak_height[i])-1)\n",
        "        freq=1/interv\n",
        "      series_data.loc[len(series_data.index)] = [i,len(self.filterer_peak_loc_2[i]),np.mean(self.filterer_peak_height[i]),np.mean(self.filterer_peak_rise_time[i]),np.mean(self.filterer_peak_fall_time[i]),np.mean(self.filterer_peak_rise_time[i])+np.mean(self.filterer_peak_fall_time[i]),interv,freq]\n",
        "    series_data=series_data.drop(columns=['ROI(#)'])\n",
        "    #series_data['peak_mean_prominence']=self.peak_mean_prominence\n",
        "    series_data['peak_height_std']=self.filterer_peak_height_std\n",
        "    #series_data['candidate_mean_prominence']=self.candidate_mean_prominence\n",
        "    #series_data['peak_std_prominence']=self.peak_std_prominence\n",
        "    series_data['W']=W\n",
        "    series_data['Z']=Z\n",
        "    series_data['X']=X\n",
        "    series_data=series_data.to_numpy()\n",
        "    series_data[np.isnan(series_data)] = 0\n",
        "    series_data[np.isinf(series_data)] = 0\n",
        "    pred=clf.predict(series_data)\n",
        "    new_idx=np.where(pred>0)\n",
        "    return [self.seq[new_idx],self.index[new_idx]]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PmNO4O_O-Amx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#对filter功能做了下调整，最好是可以把filter做成一个独立的功能\n",
        "#无filter的构建过程如下\n",
        "#data 是np array\n",
        "Caller_obj_1=PeakCaller(data,\"root/G1.hdf5\")\n",
        "Caller_obj_1.Detrender_2()\n",
        "Caller_obj_1.Find_Peak()\n",
        "#有filter的构建过程如下\n",
        "Caller_obj_1=PeakCaller(data,\"root/G1.hdf5\")\n",
        "Caller_obj_1.Detrender_2()\n",
        "Caller_obj_1.Find_Peak()\n",
        "filter_res=Caller_obj_1.Filter_Series('root/finalized_model.sav')\n",
        "new_series=filter_res[0]\n",
        "new_index=filter_res[1]\n",
        "Caller_obj_2=PeakCaller(new_series,\"root/G1_new.hdf5\",index=new_index)\n",
        "Caller_obj_2.Detrender_2()\n",
        "Caller_obj_2.Find_Peak()#使用Caller_obj_2\n",
        "#Prof 要求的即时print\n",
        "Caller_obj_1.Print_Peak(50)#这会print第51个series（从0开始），但是如果filter了那ROI#就不一定是50\n"
      ],
      "metadata": {
        "id": "JpPYo_DB-AWn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}